This API aims to detect and classify the emotion of faces. It generates entities following the "Face" data model (one for each face) that are posted to the context broker and returned as a JSON. The input of the API is the ID of an Image or a Face entity present in the context broker. If an Image is provided, the model will detect all the faces in the image and will predict their emotions. If a Face entity is provided, the coordinates of the face present in the entity will be used to locate the face and execute the model. The output will be added to the original "Face" entity and updated on the context broker.